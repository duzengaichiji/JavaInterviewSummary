# 代理模式和装饰器模式

标签（空格分隔）： java
对应代码：DesignPattern.Decorator

 - 代理模式和装饰器模式的区别与联系

> 这两种设计模式，无论是理论还是代码来看都是非常相似的；
> 下面给一个例子
> 如果画出类图，会发现二者非常相似；


> 定义两个接口，一个Child,一个Student，分别有一个功能（吃饭，学习）；
> sChild是实现了这两个接口的一个实现类；
> 那么，对于sChild这个类的装饰类，就需要持有sChild对象，并与其实现相同的接口，然后对其功能进行拓展；
> 反之，代理模式可能对其中一个功能进行拓展，然后实现Child或者Student接口的其中一个，进行拓展；
> 其实确实很相似。。只是一个比较强调类本体的拓展，另一个比较注重类的横向拓展；
> 具体可以参考Aop的实现；
> 

 - python中的装饰器

> 这里特别提一下python中的装饰器；
> 举个例子，需要计算add函数的执行时间；

    def add(a, b):        
        res = a + b        
        return res

> 如果直接对add进行拓展，就需要修改add函数本体，此时如果有其他函数，也有类似的需求，那就需要修改很多的函数，并且有很多冗余代码；

    import time
    # 定义装饰器
    def time_calc(func):
        def wrapper(*args,**kargs):
            start_time = time.time()
            f = func(*args,**kargs)
            exec_time = time.time()-start_time
            return f
        return wrapper
    # 使用装饰器
    @time_calc
    def add(a,b):
        return a+b
    ....

> 按照上面这样写，可以定义装饰器，并按照@这样的语法使用；
> 在python中， 函数也可以作为对象；
> 所以可以看到，在time_calc方法中，add方法被作为参数传入，并且在wrapper中进行功能拓展，然后一样返回func(这里就是add)的计算结果；
> 其实这样一看。。确实非常像代理模式。。。

 - lru_cache原理解析

> python中的lru_cache
> lru_cache是functools包下定义的一个装饰器，主要功能是实现一个高速缓存（递归中特别适用），在需要重复计算时，可以实现空间交换时间，效率提升巨大；

    def lru_cache(maxsize=128, typed=False):
        # maxsize定义了最存放的计算结果
        # typed表示是否将不同类型的计算结果分开存储
        if maxsize is not None and not isinstance(maxsize, int):
            raise TypeError('Expected maxsize to be an integer or None')
        # 装饰器的定义
        def decorating_function(user_function):
            wrapper = _lru_cache_wrapper(user_function, maxsize, typed, _CacheInfo) 
            # 为装饰器（装饰之后的函数）注入 __module__,__name__，等，可以不用关注
            return update_wrapper(wrapper, user_function)  
        return decorating_function

> lru_cache_wrapper的定义；
> 这里我们忽略掉lru算法的具体实现细节，可以看到，该函数其实就是装饰器的定义过程；
> 其中，利用了字典作为缓存；

    def _lru_cache_wrapper(user_function, maxsize, typed, _CacheInfo):
        # Constants shared by all lru cache instances:
        sentinel = object()          # unique object used to signal cache misses
        make_key = _make_key         # 从函数参数创建一个key  **难点3**
        PREV, NEXT, KEY, RESULT = 0, 1, 2, 3   # 连接字段名称
        # 用作缓存的字典
        cache = {}
        hits = misses = 0
        full = False
        cache_get = cache.get    # bound method to lookup a key or return None
        cache_len = cache.__len__  # 不用调用len()获取缓存大小
        lock = RLock()           # because linkedlist updates aren't threadsafe
        root = []                # root of the circular doubly linked list
        root[:] = [root, root, None, None]     # initialize by pointing to self

        if maxsize == 0:

            def wrapper(*args, **kwds):
                #不作任何缓存，直接调用函数
                nonlocal misses
                result = user_function(*args, **kwds)
                misses += 1
                return result

        elif maxsize is None:
            def wrapper(*args, **kwds):
                #不限制maxsize的简单缓存，里面没有去实现lru算法
                nonlocal hits, misses
                # 计算key，value是函数的计算结果
                key = make_key(args, kwds, typed)
                result = cache_get(key, sentinel)
                if result is not sentinel:
                    hits += 1
                    return result
                result = user_function(*args, **kwds)
                # 缓存计算结果
                cache[key] = result
                misses += 1
                return result
        else:
            def wrapper(*args, **kwds):
                # Size limited caching that tracks accesses by recency
                nonlocal root, hits, misses, full
                key = make_key(args, kwds, typed)
                with lock:
                    link = cache_get(key)
                    if link is not None:
                        # Move the link to the front of the circular queue
                        link_prev, link_next, _key, result = link
                        link_prev[NEXT] = link_next
                        link_next[PREV] = link_prev
                        last = root[PREV]
                        last[NEXT] = root[PREV] = link
                        link[PREV] = last
                        link[NEXT] = root
                        hits += 1
                        return result
                result = user_function(*args, **kwds)
                ### 其他实现细节
                misses += 1
            return result

> 缓存的key是由输入的参数进行哈希计算得到的唯一值；

    def _make_key(args, kwds, typed,
             kwd_mark = (object(),),
             fasttypes = {int, str, frozenset, type(None)},
             tuple=tuple, type=type, len=len):
        key = args # 元组
        if kwds:
            key += kwd_mark # 元组相加等于的扩展内容
            for item in kwds.items(): 
                key += item  # 把字典kv对元组添加到key元组中 
                # 得到一个类似于这样的元组:(4,6,obj,"x",4)
        if typed:  
            key += tuple(type(v) for v in args) # 把args迭代出来的数据类型扩展到key元组中
        if kwds:
            key += tuple(type(v) for v in kwds.values()) 
        elif len(key) == 1 and type(key[0]) in fasttypes: 
            return key[0]
        return _HashedSeq(key)




